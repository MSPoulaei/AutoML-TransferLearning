# =============================================================================
# Multi-Agent Transfer Learning Orchestrator - Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Default/Global OpenAI API Settings
# These are used as fallback values for all agents unless overridden
# -----------------------------------------------------------------------------
OPENAI_API_KEYS=sk-your-key-1,sk-your-key-2,sk-your-key-3
OPENAI_MODEL=gpt-4o
OPENAI_BASE_URL=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# Analyzer Agent Settings (Optional - Override defaults)
# Uncomment to use different configuration for the Analyzer Agent
# -----------------------------------------------------------------------------
# ANALYZER_API_KEYS=sk-analyzer-key-1,sk-analyzer-key-2
# ANALYZER_MODEL=gpt-4o
# ANALYZER_BASE_URL=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# Executor Agent Settings (Optional - Override defaults)
# Uncomment to use different configuration for the Executor Agent
# For example, use a lighter model for analysis tasks
# -----------------------------------------------------------------------------
# EXECUTOR_API_KEYS=sk-executor-key-1,sk-executor-key-2
# EXECUTOR_MODEL=gpt-4o-mini
# EXECUTOR_BASE_URL=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# Alternative API Providers (Example configurations)
# You can use any OpenAI-compatible API by changing the base URL
# -----------------------------------------------------------------------------

# Azure OpenAI Example:
# OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# ANALYZER_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/gpt4-deployment
# EXECUTOR_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/gpt35-deployment

# Local LLM (e.g., Ollama, LM Studio) Example:
# OPENAI_BASE_URL=http://localhost:11434/v1
# ANALYZER_MODEL=llama3.1:70b
# EXECUTOR_MODEL=llama3.1:8b

# Other providers (Anthropic Claude via OpenAI-compatible proxy, etc.):
# OPENAI_BASE_URL=https://your-proxy-url.com/v1

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
LOG_LEVEL=INFO
LOG_FILE=logs/orchestrator.log

# -----------------------------------------------------------------------------
# Directory Settings
# -----------------------------------------------------------------------------
EXPERIMENT_DIR=experiments
CHECKPOINT_DIR=checkpoints

# -----------------------------------------------------------------------------
# Hardware Settings
# -----------------------------------------------------------------------------
MEMORY_LIMIT_GB=15.0

# -----------------------------------------------------------------------------
# API Rate Limiting Settings
# -----------------------------------------------------------------------------
RATE_LIMIT_RETRY_DELAY=60
MAX_RETRIES_PER_KEY=3

# -----------------------------------------------------------------------------
# Database Settings
# -----------------------------------------------------------------------------
DATABASE_URL=sqlite:///experiments/experiments.db

# -----------------------------------------------------------------------------
# Notes:
# -----------------------------------------------------------------------------
# 1. Multiple API keys enable automatic rotation on rate limits
# 2. Each agent can have different models for cost/performance optimization
# 3. Base URL can point to OpenAI, Azure, local LLMs, or any compatible API
# 4. If agent-specific settings are not provided, defaults are used
# 5. Separate API keys per agent enable better budget control and monitoring